import streamlit as st
import pandas as pd
import os
import pickle
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# --- Importa√ß√µes do Projeto ---
from core.data.io import load_daily_activity
from core.data.database import (
    create_database_and_tables,
    insert_csv_to_sor,
    run_etl_sor_to_sot,
    run_etl_sot_to_spec_train,
    run_etl_for_predict_data,
    load_data,
    drop_database,
    get_activity_summary,
    get_daily_activity_stats
)
from core.features.preprocess import make_preprocess_pipeline
from core.models.train import train_regressor
from core.models.predict import evaluate_regressor
from core.explain.coefficients import extract_linear_importances
from core.chatbot.rules import answer_from_metrics

# --- Configura√ß√µes da P√°gina e Estado ---
st.set_page_config(page_title="An√°lise de Atividade F√≠sica - Dashboard Interativo", layout="wide")

# Estado da sess√£o
if "model_trained" not in st.session_state:
    st.session_state.model_trained = False
if "predictions_made" not in st.session_state:
    st.session_state.predictions_made = False
if "prediction_df" not in st.session_state:
    st.session_state.prediction_df = None
if "chat_messages" not in st.session_state:
    st.session_state.chat_messages = [{"role": "assistant", "content": "Ol√°! Treine um modelo ou carregue um modelo salvo para come√ßar."}]
if "metrics" not in st.session_state:
    st.session_state.metrics = None
if "importances" not in st.session_state:
    st.session_state.importances = None

# --- Diret√≥rios ---
MODEL_DIR = "model"
if not os.path.exists(MODEL_DIR):
    os.makedirs(MODEL_DIR)
MODEL_PATH = os.path.join(MODEL_DIR, "regressor_model.pickle")

# --- Fun√ß√µes Auxiliares ---
@st.cache_data
def convert_df_to_csv(df):
    return df.to_csv(index=False).encode('utf-8')

# --- T√≠tulo e Sidebar ---
st.title("üèÉ‚Äç‚ôÇÔ∏è An√°lise de Atividade F√≠sica - Dashboard Interativo")

with st.sidebar:
    st.header("1. Upload dos Dados")
    uploaded_files = st.file_uploader(
        "Envie o arquivo 'DailyActivityMerged.csv'",
        type=["csv"],
        accept_multiple_files=True
    )
    
    st.header("2. A√ß√µes do Pipeline")
    
    # --- A√á√ÉO 1: Treinar um novo modelo ---
    st.subheader("Treinar Novo Modelo")
    test_size = st.slider("Tamanho do conjunto de teste (valida√ß√£o)", 0.1, 0.4, 0.2, 0.05)
    target_variable = st.selectbox(
        "Vari√°vel Alvo para Previs√£o",
        ["Calories", "TotalSteps", "TotalActiveMinutes", "SedentaryMinutes"]
    )
    
    if st.button("Executar Treinamento"):
        df_data = None
        for file in uploaded_files:
            if "daily" in file.name.lower() or "activity" in file.name.lower():
                # Salva o arquivo temporariamente e carrega
                try:
                    # Salva o arquivo uploadado temporariamente
                    temp_path = f"temp_{file.name}"
                    with open(temp_path, "wb") as f:
                        f.write(file.getbuffer())
                    
                    # Carrega o arquivo
                    df_data = load_daily_activity(temp_path)
                    
                    # Remove o arquivo tempor√°rio
                    os.remove(temp_path)
                    
                    if df_data is not None and not df_data.empty:
                        break
                        
                except Exception as e:
                    st.error(f"Erro ao processar arquivo {file.name}: {e}")
                    continue
        
        if df_data is not None and not df_data.empty:
            with st.spinner("Processando dados e treinando o modelo..."):
                try:
                    # Executa o pipeline ETL
                    create_database_and_tables()
                    insert_csv_to_sor(df_data)
                    run_etl_sor_to_sot()
                    run_etl_sot_to_spec_train()
                    
                    # Carrega dados processados
                    df_spec_train = load_data("spec_daily_activity_train")
                    
                    # Prepara dados para treino
                    y = df_spec_train[target_variable]
                    X = df_spec_train.drop(columns=[target_variable])
                    
                    # Preprocessamento e treino
                    pre = make_preprocess_pipeline(X)
                    model, X_test, y_test = train_regressor(X, y, pre, test_size=test_size)
                    
                    # Salva o modelo
                    with open(MODEL_PATH, "wb") as f:
                        pickle.dump(model, f)
                    
                    # Avalia o modelo
                    st.session_state.metrics = evaluate_regressor(model, X_test, y_test)
                    st.session_state.importances = extract_linear_importances(model, X.columns, pre)
                    st.session_state.model_trained = True
                    st.session_state.predictions_made = False
                    st.session_state.target_variable = target_variable
                    
                    st.success(f"Modelo treinado para prever '{target_variable}' e salvo com sucesso!")
                    
                except Exception as e:
                    st.error(f"Erro durante o treinamento: {e}")
        else:
            st.warning("Nenhum dado v√°lido de atividade f√≠sica foi encontrado nos arquivos uploadados.")

    # --- A√á√ÉO 2: Fazer previs√µes com novos dados ---
    st.subheader("Fazer Previs√µes com Novos Dados")
    if st.button("Carregar Modelo e Fazer Previs√µes"):
        if not os.path.exists(MODEL_PATH):
            st.error("Nenhum modelo treinado foi encontrado! Por favor, execute o treinamento primeiro.")
        else:
            df_new_data = None
            for file in uploaded_files:
                if "daily" in file.name.lower() or "activity" in file.name.lower():
                    df_new_data = load_daily_activity(file)
            
            if df_new_data is not None:
                with st.spinner("Processando dados e fazendo previs√µes..."):
                    # Processa os dados para previs√£o
                    run_etl_for_predict_data(df_new_data)
                    df_spec_predict = load_data("spec_daily_activity_predict")
                    
                    # Carrega o modelo
                    with open(MODEL_PATH, 'rb') as f:
                        model = pickle.load(f)

                    # Faz a previs√£o (remove a vari√°vel alvo se existir)
                    X_predict = df_spec_predict.drop(columns=[st.session_state.target_variable], errors='ignore')
                    predictions = model.predict(X_predict)
                    
                    # Prepara resultado
                    result_df = df_spec_predict.copy()
                    result_df[f'Predicted_{st.session_state.target_variable}'] = predictions
                    st.session_state.prediction_df = result_df
                    st.session_state.predictions_made = True
                st.success("Previs√µes geradas com sucesso!")
            else:
                st.warning("Arquivo de atividade f√≠sica n√£o encontrado.")
    
    # --- A√á√ÉO 3: Limpeza ---
    st.header("3. Manuten√ß√£o")
    if st.button("Limpar Tudo"):
        drop_database()
        if os.path.exists(MODEL_PATH):
            os.remove(MODEL_PATH)
        st.session_state.clear()
        st.info("Banco de dados, modelo salvo e sess√£o resetados.")
        st.rerun()

# --- Abas Principais ---
tab_overview, tab_train, tab_predict, tab_analytics, tab_chat = st.tabs([
    "üìä Vis√£o Geral", "ü§ñ Resultados do Treino", "üöÄ Previs√µes", "üìà Analytics", "üí¨ Chat com o Modelo"
])

with tab_overview:
    st.header("Vis√£o Geral dos Dados de Atividade")
    if uploaded_files:
        for file in uploaded_files:
            if "daily" in file.name.lower() or "activity" in file.name.lower():
                try:
                    # Salva o arquivo temporariamente
                    temp_path = f"temp_overview_{file.name}"
                    with open(temp_path, "wb") as f:
                        f.write(file.getbuffer())
                    
                    # Carrega o arquivo
                    df_overview = load_daily_activity(temp_path)
                    
                    # Remove o arquivo tempor√°rio
                    os.remove(temp_path)
                    
                    if df_overview is not None and not df_overview.empty:
                        st.subheader(f"Arquivo: {file.name}")
                        st.dataframe(df_overview.head())
                        
                        st.subheader("Estat√≠sticas descritivas")
                        st.dataframe(df_overview.describe())
                        
                        st.subheader("Informa√ß√µes do dataset")
                        st.write(f"**Formato:** {df_overview.shape[0]} linhas √ó {df_overview.shape[1]} colunas")
                        if 'ActivityDate' in df_overview.columns:
                            st.write(f"**Per√≠odo:** {df_overview['ActivityDate'].min()} at√© {df_overview['ActivityDate'].max()}")
                        break
                    else:
                        st.warning(f"O arquivo {file.name} est√° vazio ou n√£o p√¥de ser carregado.")
                        
                except Exception as e:
                    st.error(f"Erro ao carregar arquivo {file.name}: {e}")
    else:
        st.info("Fa√ßa upload do arquivo DailyActivityMerged.csv para ver a vis√£o geral.")

with tab_train:
    st.header("M√©tricas e Import√¢ncia do Modelo")
    if not st.session_state.model_trained and st.session_state.metrics is None:
        st.info("Execute o treinamento na barra lateral para ver os resultados.")
    else:
        st.subheader(f"üìà M√©tricas para previs√£o de {st.session_state.target_variable}")
        st.json(st.session_state.metrics)
        st.subheader("üîé Import√¢ncias das Vari√°veis")
        st.dataframe(st.session_state.importances.head(15), use_container_width=True)
        
        # Visualiza√ß√£o das import√¢ncias
        if not st.session_state.importances.empty:
            st.subheader("üìä Gr√°fico de Import√¢ncias")
            importance_chart_data = st.session_state.importances.head(10).sort_values('importance', ascending=True)
            st.bar_chart(importance_chart_data.set_index('feature')['importance'])

with tab_predict:
    st.header("Previs√µes para Novos Dados")
    if not st.session_state.predictions_made:
        st.info("Fa√ßa uma previs√£o na barra lateral para ver os resultados.")
    else:
        st.subheader(f"Previs√µes de {st.session_state.target_variable}")
        st.dataframe(st.session_state.prediction_df)
        
        csv_data = convert_df_to_csv(st.session_state.prediction_df)
        st.download_button(
           label="Download das Previs√µes em CSV",
           data=csv_data,
           file_name='activity_predictions.csv',
           mime='text/csv',
        )

with tab_analytics:
    st.header("An√°lises e Estat√≠sticas")
    if st.session_state.model_trained:
        try:
            activity_summary = get_activity_summary()
            daily_stats = get_daily_activity_stats()
            
            st.subheader("üìã Resumo das Atividades")
            st.dataframe(activity_summary)
            
            st.subheader("üìà Estat√≠sticas Di√°rias")
            st.dataframe(daily_stats.head(10))
            
            # Gr√°ficos simples
            col1, col2 = st.columns(2)
            with col1:
                st.line_chart(daily_stats.set_index('ActivityDate')['DailySteps'])
                st.caption("Passos Di√°rios")
            
            with col2:
                st.line_chart(daily_stats.set_index('ActivityDate')['DailyCalories'])
                st.caption("Calorias Di√°rias")
                
        except Exception as e:
            st.warning(f"N√£o foi poss√≠vel carregar an√°lises: {e}")
    else:
        st.info("Treine um modelo primeiro para ver as an√°lises.")

with tab_chat:
    st.header("Converse com o Assistente do Modelo")
    if not st.session_state.model_trained and st.session_state.metrics is None:
        st.info("Treine um modelo primeiro para poder conversar sobre seus resultados.")
    else:
        for message in st.session_state.chat_messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        if prompt := st.chat_input(f"Pergunte sobre a previs√£o de {st.session_state.target_variable}..."):
            st.session_state.chat_messages.append({"role": "user", "content": prompt})
            response = answer_from_metrics(
                question=prompt,
                task="Regress√£o",
                metrics_df_or_dict=st.session_state.metrics,
                importances_df=st.session_state.importances,
                target_variable=st.session_state.target_variable
            )
            st.session_state.chat_messages.append({"role": "assistant", "content": response})
            st.rerun()